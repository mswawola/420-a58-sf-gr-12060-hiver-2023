{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 420-A58-SF - Algorithmes d'apprentissage non supervisé - Hiver 2023 - Spécialisation technique en Intelligence Artificielle<br/>\n",
    "**Objectif: cette séance de travaux pratiques consiste en l'implémentation et la mise en oeuvre de l'algorithme LSH sur le jeu de données people_wiki. Les performances de regroupement et les temps d'exécution seront évalués**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Le reste des modules sera importé au fur et à mesure des exercices ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour rappel, l'archive `people.zip` contient 4 fichiers:\n",
    "\n",
    "* **people_wiki.csv**: jeu de données consituté des pages Wikipedia de personnalités\n",
    "* **people_wiki_map_index_to_word.json**: mapping entre les mots et les indices\n",
    "* **people_wiki_word_count.npz**: vecteurs d'occurence des mots (word count) pour chaque document\n",
    "* **people_wiki_tf_idf.npz**: vecteurs TF-IDF pour chaque document\n",
    "\n",
    "Dans l'énoncé de ce TP, les mots \"article\" et \"document\" sont interchangeables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, la **représentation TF-IDF** sera utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from helpers import load_sparse_csr\n",
    "\n",
    "# Chargement du jeu de données\n",
    "wiki = pd.read_csv('../../data/people/people_wiki.csv')\n",
    "wiki.index.name = 'id'\n",
    "\n",
    "# Chargement des représentations TF-IDF\n",
    "corpus = load_sparse_csr('../../data/people/people_wiki_tf_idf.npz')\n",
    "\n",
    "# Chargement du mapping entre les mots et les indices\n",
    "with open('../../data/people/people_wiki_map_index_to_word.json') as f:\n",
    "     map_index_to_word = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Modèle LSH - Travail préliminaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSH effectue une recherche de type plus proches voisins efficace en partitionnant de manière aléatoire toutes les observations dans différents **bins**. Nous allons ici construire une variante populaire de LSH connue sous le nom de **projection binaire aléatoire** (random binary projection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2-1 - Créer une fonction permettant de générer une collection de vecteurs aléatoires à partir d'une distribution gaussienne. Les paramètres de cette fonction sont `dim` (dimension des vecteurs) et `num_vector` (nombre de vecteurs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 2 lignes de code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2-2 - Afficher quelques vecteurs, par exemple 3 vecteurs de dimension 5. Afin de permettre la reproductibilité des résultats, nous choisissons un seed de 2020.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "# Compléter cette cellule ~ 1 ligne de code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2-3 - Générer un nombre de vecteurs aléatoires de la même dimension que la taille du vocabulaire et permettant d'encoder sur 16 bits l'index du bin de chaque documents.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "# Compléter cette cellule ~ 1-2 lignes de code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous aimerions maintenant décider dans quel bin le **document d'indice 0** devrait se retrouver. Ayant les 16 vecteurs aléatoires générés précédement, nous avons 16 bits pour représenter l'index du bin. Le premier bit est donné par **le signe du produit scalaire** entre le premier vecteur aléatoire et le vecteur TF-IDF du document.  Le deuxieme bit est donné par **le signe du produit scalaire** entre le deuxieme vecteur aléatoire et le vecteur TF-IDF du document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2-4 - Calculer le premier et le second bit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 2-3 lignes de code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2-5 - En utilisant une méthode vectorisée, calculer tous les bits du bin correspondant au document d'indice 0. Utiliser les entiers 0/1 pour représenter les bits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 1 ligne de code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2-6 - En utilisant à nouveau une méthode vectorisée, calculer tous les bins pour l'ensemble des documents du jeu de données. Afficher la representation décimale (index du bin) des 10 premiers documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://lh3.googleusercontent.com/proxy/133dre9Rzr5Olqa_XFHe8kaZzZxbcdh23QcbPIOD_AZ5oAruazhI5tqmDyCZbixE72tRI_mG3zutbz-bn946pfQxikGWYZcLoq1ZkfeZj9oUtzsn2NSqUGD3eySkMcINIUYJ6g4gYhjsJMbpYbwSYe9XqNwEFTZrb3_ZtEOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 3-5 lignes de code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Modèle LSH - Entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nous basant sur le travail préliminaire, nous pouvons maintenant compiler la liste des documents appartiennant à chaque bin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 3 - Créer une fonction `train_lsh` prenant en paramètre le jeu de données, le nombre de bits d'encodage et un seed par défaut à 2020**\n",
    "**La fonction devra, pour chaque document du jeu de données:**\n",
    "* **Obtenir l'indice du bin pour le document courant**\n",
    "* **Obtenir la liste des ids des documents associés avec ce bin. Si la liste n'existe pas, créer une liste vide**\n",
    "* **Ajouter l'id du document courant à la fin de la liste**\n",
    "\n",
    "**La fonction devra retourner la structure de données suivante:**\n",
    "\n",
    "`{'data': le jeu de données,\n",
    " 'bin_index_bits': les indices des bins au format binaire,\n",
    " 'bin_indices': les indices des bins au format décimal,\n",
    " 'table': table de hachage (ids des documents pour chaque bin),\n",
    " 'random_vectors': les vecteurs aléatoires,\n",
    " 'num_vector': le nombre de vecteurs (taille de l'encodage)\n",
    "}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 20 lignes de code\n",
    "def train_lsh(data, num_vector=16, seed=2020):\n",
    "    \n",
    "    # Generer les vecteurs aleatoires\n",
    "    \n",
    "    # Partitionner les documents dans les bins (binaire et decimal)\n",
    "    \n",
    "    # Table de hachage\n",
    "    table = {}\n",
    "    # Iteration\n",
    "    \n",
    "    model = {'data': data,\n",
    "     'bin_index_bits': None,\n",
    "     'bin_indices': None,\n",
    "     'table': None,\n",
    "     'random_vectors': None,\n",
    "     'num_vector': None\n",
    "    }\n",
    "                                          \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécutez la cellule suivante pour vérifier l'implémentation de votre fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import checkcode_ex3\n",
    "\n",
    "model = train_lsh(corpus, num_vector=16, seed=143)\n",
    "checkcode_ex3(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Modèle LSH - Inspection des bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 4-1 - Quel est l'index du bin contenant l'id du document correspondant à la page de Barack Obama ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 1-2 lignes de code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 4-2 - Le documents de Barack Obama et de Joe Biden sont-ils dans le même bin ? Si non, comparer la représentation binaire des bins pour ces deux personalités**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 5 lignes de code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 4-3 - Quels sont les documents présents dans le même bin que Barack Obama ? Sont-ils nécéssairement plus similaires que Joe Biden ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 5 lignes de code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 4-4 - Afficher les similarités cosinus avec le document de Barack Obama pour chaque document présents dans le même bin. Comparer avec Joe Biden. La fonction cosine_distance est fournie dans le fichier `helpers.py`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 7-10 lignes de code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Modèle LSH - Recherche des plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie de la séance de travaux pratiques sera l'occasion de rechercher les plus proches voisins en se basant sur le modele LSH. La logique qui sera implémentée, consistant en l'inversion de bits, est la suivante:\n",
    "1. Soit L la représentation binaire du bin contenant le document requête.\n",
    "2. Trouver tous les documents du bin L.\n",
    "3. Trouver tous les documents du bin  dont la représentation diffère de L de 1 bit.\n",
    "4. Trouver tous les documents du bin  dont la représentation diffère de L de 2 bits.\n",
    "5. etc ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'obtenir les bins différant du bin \"requête\" d'un certain nombre de bits, nous pouvons utiliser [`itertools.combinations`](https://docs.python.org/3/library/itertools.html#itertools.combinations), qui produit tous les sous-ensembles possibles d'une liste donnée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choisir le rayon de recherche `r`. Ceci détermine le nombre de bits différents entre deux vecteurs.\n",
    "2. Pour chaque sous ensemble (n_1, n_2, ..., n_r) de la liste [0, 1, 2, ..., num_vector-1], effectuer:\n",
    "   * Inverser le bits (n_1, n_2, ..., n_r) du bin requête pour produire un nouveau vecteur.\n",
    "   * Obtenir la liste des documents appartenant au bin indexé par ce nouveau vecteur.\n",
    "   * Ajouter tous ce doucments à l'ensemble \"candidat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque résultat de la cellule suivante est un 3-tuple indiquant la position où de le bin candidat diffère du bin requête. Par exemple, (0, 1, 3) indique que le bin candidat diffère du bin requête sur les premier, second et quatrième bits. Afin d'illustrer le concept détaillé ci-dessus, inspectez le résultat de la cellule ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "num_vector = 16\n",
    "search_radius = 3\n",
    "\n",
    "for diff in combinations(range(num_vector), search_radius):\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 5-1 - La fonction ci-dessous recherche les bins voisins du bin requête dans un rayon déterminé. Compléter cette fonction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy  # deep copies\n",
    "\n",
    "def search_nearby_bins(query_bin_bits, table, search_radius=2, initial_candidates=set()):\n",
    "    \"\"\"\n",
    "    Pour un vecteur requête donné et un model LSH entraîné,\n",
    "    retourne tous les candidats, voisins de la requête dans tous les bins du rayon de recherche.\n",
    "    \n",
    "    Exemple:\n",
    "    --------\n",
    "    >>> model = train_lsh(corpus, num_vector=16, seed=143)\n",
    "    >>> q = model['bin_index_bits'][0]  # vecteur du premier document\n",
    "  \n",
    "    >>> candidates = search_nearby_bins(q, model['table'])\n",
    "    \"\"\"\n",
    "    num_vector = len(query_bin_bits)\n",
    "    powers_of_two = 1 << np.arange(num_vector-1, -1, -1)\n",
    "    \n",
    "    # Permet de fournir un ensemble de candidats initial\n",
    "    candidate_set = copy(initial_candidates)\n",
    "    \n",
    "    for different_bits in combinations(range(num_vector), search_radius):       \n",
    "        # Inverser le bits (n_1, n_2, ..., n_r) du bin requête pour produire un nouveau vecteur.\n",
    "        alternate_bits = copy(query_bin_bits)\n",
    "        for i in different_bits:\n",
    "            # ------------------------------------------------------------------------------\n",
    "            # ICI: code pour l'inversion de bits ~ 1 ligne\n",
    "            # ------------------------------------------------------------------------------\n",
    "        \n",
    "        # Conversion du nouveau vecteur binaire en index (entier)\n",
    "        nearby_bin = alternate_bits.dot(powers_of_two)\n",
    "        \n",
    "        if nearby_bin in table:\n",
    "            # -------------------------------------------------------------------------------\n",
    "            # ICI: code pour mise à jour de candidate_set avec les documents bin\n",
    "            # -------------------------------------------------------------------------------\n",
    "            \n",
    "    return candidate_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécutez la cellule suivante pour vérifier l'implémentation de votre fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import checkcode_ex5_searchradius0, checkcode_ex5_searchradius1\n",
    "\n",
    "candidate_set = checkcode_ex5_searchradius0(model, search_nearby_bins)\n",
    "checkcode_ex5_searchradius1(model, search_nearby_bins, candidate_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 5-2 - Compléter la fonction ci-dessous, puis réaliser une requête pour trouver les plus proches voisins du document sur Obama. Utilisez un rayon de 3 et affichez les 10 plus proches. Afficher le nom et la distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances \n",
    "\n",
    "def query(vec, model, k, max_search_radius):\n",
    "  \n",
    "    data = model['data']\n",
    "    table = model['table']\n",
    "    random_vectors = model['random_vectors']\n",
    "    num_vector = random_vectors.shape[1]\n",
    "    \n",
    "    # Calcul l'index du bin (en bianire) du vecteur de requête\n",
    "    bin_index_bits = (vec.dot(random_vectors) >= 0).flatten()\n",
    "   \n",
    "    # Recherche de bin à proximité et collecte des candidats\n",
    "    candidate_set = set()\n",
    "    for search_radius in range(0, max_search_radius+1):\n",
    "        candidate_set = search_nearby_bins(bin_index_bits, table, search_radius, initial_candidates=candidate_set)\n",
    "   \n",
    "    # Trie les candidats par leur distance à la requête\n",
    "    nearest_neighbors = pd.DataFrame(candidate_set, columns=['id'])\n",
    "    candidates = data[list(candidate_set),:]\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------\n",
    "    # ICI: nearest_neighbors['distance'] = ... calcul des distances entre candidates et vec ~ 1 ligne\n",
    "    # -------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    return nearest_neighbors.nsmallest(k, 'distance'), len(candidate_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 2-3 lignes de code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Modèle LSH - Expérimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les sections suivantes, nous avons implémenté quelques expériences afin que vous puissiez acquérir une intuition sur le comportement de votre implémentation LSH dans différentes situations. Cela vous aidera à comprendre l'effet de la recherche de bins voisins et les performances de LSH par rapport au calcul des voisins les plus proches à l'aide d'une recherche par force brute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment la recherche dans les bins à proximité affecte-t-elle le résultat du LSH? Trois variables sont affectées par le rayon de recherche:\n",
    "\n",
    "* Nombre de documents candidats considérés\n",
    "* Temps de requête\n",
    "* Distance des voisins approximatifs de la requête\n",
    "\n",
    "Exécutons LSH plusieurs fois, chacun avec des rayons différents pour la recherche des bins voisins. Nous mesurerons les trois variables comme discuté ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "num_candidates_history = []\n",
    "query_time_history = []\n",
    "max_distance_from_query_history = []\n",
    "min_distance_from_query_history = []\n",
    "average_distance_from_query_history = []\n",
    "\n",
    "for max_search_radius in range(17):\n",
    "    start=time.time()\n",
    "    # Exécute la requête LSH pour Barack Obama\n",
    "    result, num_candidates = query(corpus[35817,:], model, k=10, max_search_radius=max_search_radius)\n",
    "    end=time.time()\n",
    "    query_time = end-start\n",
    "    \n",
    "    print(f'Radius: {max_search_radius}')\n",
    "    # Afficher les 10 NN incluant l'id du document et le nom\n",
    "    print(result.join(wiki, on='id', how='inner').sort_values(by='distance', ascending=True)[['distance','name']])\n",
    "    \n",
    "    # Obtention des  statistiques sur les 10 NN\n",
    "    average_distance_from_query = result['distance'][1:].mean()\n",
    "    max_distance_from_query = result['distance'][1:].max()\n",
    "    min_distance_from_query = result['distance'][1:].min()\n",
    "    \n",
    "    num_candidates_history.append(num_candidates)\n",
    "    query_time_history.append(query_time)\n",
    "    average_distance_from_query_history.append(average_distance_from_query)\n",
    "    max_distance_from_query_history.append(max_distance_from_query)\n",
    "    min_distance_from_query_history.append(min_distance_from_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(num_candidates_history, linewidth=4)\n",
    "plt.xlabel('Rayon de recherche')\n",
    "plt.ylabel('Nombre de documents cherchés')\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(query_time_history, linewidth=4)\n",
    "plt.xlabel('Rayon de recherche')\n",
    "plt.ylabel('Query time (seconds)')\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(average_distance_from_query_history, linewidth=4, label='Moyenne des 10 voisins')\n",
    "plt.plot(max_distance_from_query_history, linewidth=4, label='Plus loin des 10 voisins')\n",
    "plt.plot(min_distance_from_query_history, linewidth=4, label='Plus proche des 10 voisins')\n",
    "plt.xlabel('Rayon de recherche')\n",
    "plt.ylabel('Distance cosinus des voisins')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 6-1 - Quel est le plus petit rayon de recherche qui a donné le voisin le plus proche correct, à savoir Joe Biden??**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 6-2 - Supposons que notre objectif était de produire 10 voisins les plus proches approximatifs dont la distance moyenne par rapport au document de requête est inférieure à 0,01 de la moyenne des 10 vrais voisins les plus proches. Pour Barack Obama, les 10 vrais voisins les plus proches sont en moyenne d'environ 0,77. Quel était le plus petit rayon de recherche pour Barack Obama qui a produit une distance moyenne de 0,78 ou mieux?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Modèle LSH - Métriques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyse ci-dessus est limitée par le fait qu'elle a été exécutée avec une seule requête, à savoir Barack Obama. Nous devons répéter l'analyse pour l'intégralité des données. Itérer sur tous les documents prendrait beaucoup de temps, alors choisissons au hasard 10 documents pour notre analyse.\n",
    "\n",
    "Pour chaque document, nous calculons d'abord les 25 vrais voisins les plus proches, puis exécutons LSH plusieurs fois. Nous examinons deux mesures:\n",
    "\n",
    "* Précision @ 10: Combien des 10 voisins donnés par LSH sont parmi les 25 vrais voisins les plus proches?\n",
    "* Distance cosinus moyenne des voisins de la requête\n",
    "\n",
    "Ensuite, nous exécutons LSH plusieurs fois avec différents rayons de recherche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_force_query(vec, data, k):\n",
    "    num_data_points = data.shape[0]\n",
    "    \n",
    "    # Calcul les distances pour tous les points du jeu de données\n",
    "    nearest_neighbors = pd.DataFrame(range(num_data_points), columns=['id'])\n",
    "    nearest_neighbors['distance'] = pairwise_distances(data, vec, metric='cosine').flatten()\n",
    "    \n",
    "    return nearest_neighbors.nsmallest(k, 'distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule suivante exécutera LSH avec plusieurs rayons de recherche et calculera les métriques de qualité pour chaque exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_radius = 17\n",
    "precision = {i:[] for i in range(max_radius)}\n",
    "average_distance  = {i:[] for i in range(max_radius)}\n",
    "query_time  = {i:[] for i in range(max_radius)}\n",
    "\n",
    "np.random.seed(0)\n",
    "num_queries = 10\n",
    "for i, ix in enumerate(np.random.choice(corpus.shape[0], num_queries, replace=False)):\n",
    "    print('%s / %s' % (i, num_queries))\n",
    "    ground_truth = set(brute_force_query(corpus[ix,:], corpus, k=25)['id'])\n",
    "    # Obtient l'ensemble des 25 véritables plus proches voisins\n",
    "    \n",
    "    for r in range(1,max_radius):\n",
    "        start = time.time()\n",
    "        result, num_candidates = query(corpus[ix,:], model, k=10, max_search_radius=r)\n",
    "        end = time.time()\n",
    "\n",
    "        query_time[r].append(end-start)\n",
    "        # precision = (# of neighbors both in result and ground_truth)/10.0\n",
    "        precision[r].append(len(set(result['id']) & ground_truth)/10.0)\n",
    "        average_distance[r].append(result['distance'][1:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(1,17), [np.mean(average_distance[i]) for i in range(1,17)], linewidth=4, label='Average over 10 neighbors')\n",
    "plt.xlabel('Search radius')\n",
    "plt.ylabel('Cosine distance')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(1,17), [np.mean(precision[i]) for i in range(1,17)], linewidth=4, label='Precison@10')\n",
    "plt.xlabel('Search radius')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(1,17), [np.mean(query_time[i]) for i in range(1,17)], linewidth=4, label='Query time')\n",
    "plt.xlabel('Search radius')\n",
    "plt.ylabel('Query time (seconds)')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - Modèle LSH - Effets du nombre de vecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons maintenant le paramètre restant: le nombre de vecteurs aléatoires. Nous exécutons LSH avec un nombre différent de vecteurs aléatoires, allant de 5 à 20. Nous fixons le rayon de recherche à 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = {i:[] for i in range(5,20)}\n",
    "average_distance  = {i:[] for i in range(5,20)}\n",
    "query_time = {i:[] for i in range(5,20)}\n",
    "num_candidates_history = {i:[] for i in range(5,20)}\n",
    "ground_truth = {}\n",
    "\n",
    "np.random.seed(0)\n",
    "num_queries = 10\n",
    "docs = np.random.choice(corpus.shape[0], num_queries, replace=False)\n",
    "\n",
    "for i, ix in enumerate(docs):\n",
    "    ground_truth[ix] = set(brute_force_query(corpus[ix,:], corpus, k=25)['id'])\n",
    "    # Obtient l'ensemble des 25 véritables plus proches voisins\n",
    "\n",
    "for num_vector in range(5,20):\n",
    "    print('num_vector = %s' % (num_vector))\n",
    "    model = train_lsh(corpus, num_vector, seed=143)\n",
    "    \n",
    "    for i, ix in enumerate(docs):\n",
    "        start = time.time()\n",
    "        result, num_candidates = query(corpus[ix,:], model, k=10, max_search_radius=3)\n",
    "        end = time.time()\n",
    "        \n",
    "        query_time[num_vector].append(end-start)\n",
    "        precision[num_vector].append(len(set(result['id']) & ground_truth[ix])/10.0)\n",
    "        average_distance[num_vector].append(result['distance'][1:].mean())\n",
    "        num_candidates_history[num_vector].append(num_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(5,20), [np.mean(average_distance[i]) for i in range(5,20)], linewidth=4, label='Average over 10 neighbors')\n",
    "plt.xlabel('# of random vectors')\n",
    "plt.ylabel('Cosine distance')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(5,20), [np.mean(precision[i]) for i in range(5,20)], linewidth=4, label='Precison@10')\n",
    "plt.xlabel('# of random vectors')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(5,20), [np.mean(query_time[i]) for i in range(5,20)], linewidth=4, label='Query time (seconds)')\n",
    "plt.xlabel('# of random vectors')\n",
    "plt.ylabel('Query time (seconds)')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(5,20), [np.mean(num_candidates_history[i]) for i in range(5,20)], linewidth=4,\n",
    "         label='# of documents searched')\n",
    "plt.xlabel('# of random vectors')\n",
    "plt.ylabel('# of documents searched')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du TP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
